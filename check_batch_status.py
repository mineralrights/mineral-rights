#!/usr/bin/env python3
"""
Check Batch Processing Status

This script checks the status of the running batch processing job.
"""

import os
import json
import time
from setup_gcs_batch import GCSBatchProcessingService

def check_job_status():
    """Check the status of the current batch processing job"""
    try:
        # Load job info
        if not os.path.exists('batch_job_info.json'):
            print("âŒ No batch job found. Run setup_gcs_batch.py first.")
            return False
        
        with open('batch_job_info.json', 'r') as f:
            job_info = json.load(f)
        
        print("ðŸ“Š Checking Batch Processing Status")
        print("=" * 40)
        print(f"ðŸ“‹ Job ID: {job_info['job_id']}")
        print(f"ðŸ“ Input: {job_info['input_uri']}")
        print(f"ðŸ“ Output: {job_info['output_uri']}")
        print(f"â° Started: {time.ctime(job_info['created_at'])}")
        
        # Create service
        batch_service = GCSBatchProcessingService(
            project_id="381937358877",
            location="us",
            bucket_name=job_info['bucket_name']
        )
        
        # Check status
        print(f"\nðŸ” Checking job status...")
        status = batch_service.check_job_status(job_info['job_id'])
        
        print(f"ðŸ“Š Status: {status}")
        
        if status == "COMPLETED":
            print(f"\nðŸŽ‰ Job completed! Downloading results...")
            results = batch_service.download_results(job_info['output_uri'])
            
            print(f"\nðŸ“Š Results Summary:")
            print(f"   - Total entities found: {len(results)}")
            
            # Show first few results
            print(f"\nðŸ” Sample Results:")
            for i, result in enumerate(results[:10]):
                print(f"   - {i+1}. {result['type']}: confidence {result['confidence']:.3f}")
                if result['page_refs']:
                    pages = [ref.get('page', '?') for ref in result['page_refs']]
                    print(f"     Pages: {pages}")
            
            if len(results) > 10:
                print(f"   ... and {len(results) - 10} more")
            
            # Save results
            with open('batch_results.json', 'w') as f:
                json.dump(results, f, indent=2)
            print(f"\nðŸ’¾ Results saved to: batch_results.json")
            
            return True
            
        elif status == "RUNNING":
            print(f"\nâ³ Job is still running...")
            print(f"   - This is normal for large documents")
            print(f"   - Check again in a few minutes")
            return False
            
        elif "FAILED" in status:
            print(f"\nâŒ Job failed: {status}")
            return False
            
        else:
            print(f"\nâ“ Unknown status: {status}")
            return False
            
    except Exception as e:
        print(f"âŒ Error checking job status: {e}")
        import traceback
        traceback.print_exc()
        return False

def monitor_job():
    """Monitor the job until completion"""
    print("ðŸ”„ Monitoring batch processing job...")
    print("Press Ctrl+C to stop monitoring")
    
    try:
        while True:
            completed = check_job_status()
            if completed:
                print("\nâœ… Job completed successfully!")
                break
            
            print(f"\nâ³ Waiting 30 seconds before next check...")
            time.sleep(30)
            
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  Monitoring stopped by user")
        print(f"ðŸ’¡ You can run 'python check_batch_status.py' later to check status")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "monitor":
        monitor_job()
    else:
        check_job_status()
